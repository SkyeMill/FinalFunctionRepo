# # -*- coding: utf-8 -*-
# """Preprocessing Steps.ipynb

# Automatically generated by Colab.

# Original file is located at
#     https://colab.research.google.com/drive/1V6RX3OFNhKMrZUXFFlzc2ey6akjM6kGV
# """

# import numpy as np
# import pandas as pd
# import matplotlib.pyplot as plt
# np.set_printoptions(suppress=True, linewidth=200, edgeitems=100)

# df = pd.read_csv('') #add in the CSV for preprocessing
# df

# import numpy as np
# import pandas as pd
# np.set_printoptions(suppress=True, linewidth=200, edgeitems=100)

# # Pipeline and column transformer
# from sklearn.pipeline import Pipeline, make_pipeline
# from sklearn.compose import ColumnTransformer, make_column_transformer

# # Data transformers
# from sklearn.impute import SimpleImputer
# from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler, label_binarize
# from sklearn.decomposition import PCA
# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA

# # Data splitter and model evaluator
# from sklearn.model_selection import train_test_split, validation_curve, learning_curve, GridSearchCV

# # Learning models
# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

# # Performance metrics
# from sklearn.metrics import log_loss, roc_auc_score

# # Import necessary modules
# from sklearn.base import BaseEstimator, TransformerMixin

# # Create a class to select numerical or categorical columns
# class PandasDataFrameSelector(BaseEstimator, TransformerMixin):
#     def __init__(self, attribute_names):
#         self.attribute_names = attribute_names
#     def fit(self, X, y=None):
#         return self
#     def transform(self, X):
#         return X[self.attribute_names].values

# # Group different types of data here.  You can create more than 3 groups if you need to process different features differently.
# # The idea is that each feature group will go through a separate pipeline
# nom_col = ['Ethnicity']            # nominal features
# ord_col = ['ParentalEducation', 'ParentalSupport']                        # ordinal features
# num_col = ['Age', 'StudyTimeWeekly','Absences'] # numerical features
# other_col = ['Gender', 'Tutoring', 'Extracurricular', 'Sports', 'Music', 'Volunteering']
# # Note: If you copy column names into the above list manually, be sure to copy the exact names without duplications.

# # Define X and y
# X = df[nom_col + ord_col + num_col + other_col]
# y = df['GradeClass']

# X_train, X_test, y_train, y_test = train_test_split(X, y,
#                                                     test_size=0.3,
#                                                     stratify=y,
#                                                     random_state=1
#                                                    )

# nom_pipe = make_pipeline(SimpleImputer(strategy='most_frequent'),
#                          OneHotEncoder(handle_unknown='ignore')
#                         )
# ord_pipe = make_pipeline(SimpleImputer(strategy='median'),
#                          StandardScaler()
#                         )
# num_pipe = make_pipeline(SimpleImputer(strategy='mean'),
#                          StandardScaler()
#                         )

# # Combine pipelines using a ColumnTransformer
# preprocessor = ColumnTransformer(
#     transformers=[
#         ('nominal', nom_pipe, nom_col),
#         ('ordinal', ord_pipe, ord_col),
#         ('numerical', num_pipe, num_col),
#     ],
#     remainder='passthrough'  # Keep all other columns
# )

# # Create a pipeline with the preprocessor
# full_pipeline = make_pipeline(preprocessor)

print("Preprocessing")